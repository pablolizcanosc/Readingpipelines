{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "########## MEANING AND GRAMMAR\n",
    "############################################################\n",
    "\n",
    "from googletrans import Translator\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.tokens import Token\n",
    "import random\n",
    "from datetime import date\n",
    "import sys\n",
    "import codecs\n",
    "import sqlite3\n",
    "\n",
    "def VERBpipeline(x):\n",
    "    x._.att_li[\"aux_labels\"] = []\n",
    "    if x._.att_li[\"family\"]==\"\": #only words without previous category can become main\n",
    "        x._.att_li[\"family\"] = \"VERB\"\n",
    "        x._.att_li[\"subtype\"] = \"MAIN\"\n",
    "    morphoverb = x.morph.to_dict()\n",
    "    x._.att_li[\"aux_labels\"] += [morphoverb[i] for i in morphoverb if i in ['Mood','Tense', 'VerbForm']] #xche cera un upper???\n",
    "\n",
    "    for i in x.children:\n",
    "        if i.dep_ == \"svp\": #separable verbs\n",
    "            i._.att_li[\"family\"] = \"VERB\" #+= [\"SEPARABLE_VERB_p\"]\n",
    "            i._.att_li[\"subtype\"] = \"SVP\"\n",
    "            i._.questioncategory = [\"SVP\"]\n",
    "\n",
    "            x._.att_li[\"aux_labels\"] += [\"SEPARABLE_VERB\"]\n",
    "            x._.att_li[\"aux_string\"] = i.text\n",
    "        elif i.pos_ == \"AUX\": #auxiliary verbs\n",
    "            i._.att_li[\"family\"] = \"VERB\"\n",
    "            i._.att_li[\"subtype\"] = \"AUX\"\n",
    "        else: #Reflexive verbs\n",
    "            adder=0\n",
    "            morphochild = i.morph.to_dict()\n",
    "            if morphochild.get(\"Reflex\",\"No\")==\"Yes\":\n",
    "                x._.att_li[\"aux_labels\"] += [\"REFLEXIVE_VERB\"]\n",
    "                i._.att_li[\"family\"] = \"VERB\"\n",
    "                i._.att_li[\"subtype\"] = \"REFLEXPRON\"\n",
    "            elif (\"Number\" in morphoverb) and (\"Person\" in morphoverb):\n",
    "                if (i.pos_==\"PRON\") and (morphochild[\"PronType\"]==\"Prs\")and (morphochild[\"PronType\"] in [\"Acc\",\"Dat\"]):\n",
    "                    for j in [\"Number\",\"Person\"]:\n",
    "                        adder+=(morphochild[j]==morphoverb[j])\n",
    "                    if adder == 2:\n",
    "                        #i._.extra_info += i._.extra_info+[\"REFLEXIVE_VERB_p\"]\n",
    "                        i._.att_li[\"family\"] = \"VERB\"\n",
    "                        i._.att_li[\"subtype\"] = \"REFLEXPRON\"\n",
    "                        x._.att_li[\"aux_labels\"] += [\"REFLEXIVE_VERB\"]\n",
    "\n",
    "\n",
    "def nonVERBpipeline(x):\n",
    "    x._.att_li[\"aux_labels\"] = []\n",
    "    if x.pos_ in [\"NOUN\", \"PRON\", \"PROPN\", \"ADJ\", \"DET\"]: #noun group elements\n",
    "        if x._.att_li[\"family\"] == \"\":\n",
    "            x._.att_li[\"family\"] = \"NOUN\"\n",
    "            x._.att_li[\"subtype\"] = x.pos_\n",
    "        morphodict = x.morph.to_dict()\n",
    "        x._.att_li[\"aux_labels\"] += [morphodict[i] for i in morphodict if i in [\"Gender\",\"Case\",\"Number\"]] #xche cera un upper???\n",
    "    elif x.pos_ not in [\"X\",\"SPACE\",\"PUNCT\"]: #il resto\n",
    "        if x._.att_li[\"family\"] == \"\":\n",
    "            x._.att_li[\"family\"] = \"OTHERS\"\n",
    "            x._.att_li[\"subtype\"] = x.pos_\n",
    "            x._.questioncategory = [\"OTHERS\", x.pos_]\n",
    "\n",
    "def computeattli(doc):\n",
    "    for i in doc:\n",
    "        if i.pos_ in [\"VERB\",\"AUX\"]:\n",
    "            VERBpipeline(i)\n",
    "        else:\n",
    "            nonVERBpipeline(i)\n",
    "\n",
    "\n",
    "\n",
    "def gettranslatednumbered(text_with_n):\n",
    "\n",
    "    translator = Translator()\n",
    "    final = \"\"\n",
    "    final_t = \"\"\n",
    "    elements = text_with_n.split(\"\\n\")\n",
    "    nr_el = len(elements)\n",
    "    ciphers = len(str(nr_el))\n",
    "    for i in range(nr_el):\n",
    "        if elements[i]!=\"\":\n",
    "            final+= \"(\"+str(i).zfill(ciphers)+\") \"+elements[i]+\"</br>\"\n",
    "            final_t+= \"(\"+str(i).zfill(ciphers)+\") \"+translator.translate(elements[i]).text+\"</br>\"\n",
    "        else:\n",
    "            final+=\"</br>\"\n",
    "            final_t+=\"</br>\"\n",
    "    return final,final_t\n",
    "\n",
    "def numberparagraphs(text_with_n):\n",
    "    final = \"\"\n",
    "    elements = text_with_n.split(\"\\n\")\n",
    "    nr_el = len(elements)\n",
    "    ciphers = len(str(nr_el))\n",
    "    for i in range(nr_el):\n",
    "        if elements[i]!=\"\":\n",
    "            final+= \"(\"+str(i).zfill(ciphers)+\") \"+elements[i]+\"</br>\"\n",
    "        else:\n",
    "            final+=\"</br>\"\n",
    "    return final\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################################################\n",
    "### VOCABULARY\n",
    "##################################################\n",
    "\n",
    "import wordfreq\n",
    "import numpy as np\n",
    "import simplemma\n",
    "langdata = simplemma.load_data('de')\n",
    "\n",
    "def basewordfreq(x):\n",
    "    if x.pos_ not in [\"NUM\",\"X\",\"PROPN\",\"SPACE\",\"PUNCT\"] and not ((x._.att_li[\"family\"] == \"VERB\") and (x._.att_li[\"subtype\"] == \"SVP\")):\n",
    "        word_candidates = [x.lemma_, x.text, simplemma.lemmatize(x.text, langdata)]\n",
    "        if \"SEPARABLE_VERB\" in x._.att_li[\"aux_labels\"]:\n",
    "            word_candidates = [x._.att_li[\"aux_string\"]+i for i in word_candidates]\n",
    "        maxfreq = max([wordfreq.word_frequency(i,\"de\") for i in word_candidates])\n",
    "                      \n",
    "        return x, x._.att_li[\"family\"], list(set(word_candidates)), maxfreq\n",
    "    return x, np.nan, np.nan, np.nan\n",
    "\n",
    "def isanewword(x):\n",
    "    x._.newword=True\n",
    "    if len(x._.questioncategory)==0:\n",
    "        x._.questioncategory = [\"NEW\"]\n",
    "    else:\n",
    "        x._.questioncategory += [\"NEW\"]\n",
    "    if (x._.att_li[\"family\"] == \"VERB\") and (x._.att_li[\"subtype\"] == \"MAIN\"):\n",
    "        for i in x.children:\n",
    "            if (i._.att_li[\"family\"] == \"VERB\") and (i._.att_li[\"subtype\"] in [\"REFLEXPRON\", \"SVP\"]):\n",
    "                i._.newword = True\n",
    "                if len(i._.questioncategory)==0:\n",
    "                    i._.questioncategory = [\"NEW\"]\n",
    "                else: #controllare che new non c'è già\n",
    "                    x._.questioncategory += [\"NEW\"]                \n",
    "    \n",
    "def processvocabulary(doc):\n",
    "    try:\n",
    "        history = pd.read_csv(\"history.csv\",sep=\"|\", index_col = 0)\n",
    "        profile = pd.read_csv(\"profile.csv\",sep=\"|\", index_col = 0)\n",
    "\n",
    "        dfvocab = pd.Series(doc).apply(basewordfreq).apply(pd.Series)\n",
    "        nr_words = len(dfvocab.dropna())\n",
    "        dfvocab = dfvocab.explode(2)\n",
    "        \n",
    "        dfvocab.columns = [\"token\", \"family\", \"base\", \"freq\"]\n",
    "\n",
    "        dfaux = dfvocab.groupby([\"family\", \"base\"]).agg({\"freq\":[\"count\",\"max\"]})\n",
    "        dfaux.columns = [\"nr_appearances\", \"freq_corpus\"]\n",
    "        dfaux=dfaux.reset_index()\n",
    "        dfaux[\"freq_text\"]=dfaux[\"nr_appearances\"]/nr_words\n",
    "        \n",
    "        history.columns = [\"family\", \"base\", \"nr_appearances_old\", \"freq_corpus_old\",\"highlighted\"]\n",
    "        dfaux = pd.merge(dfaux,history, on= [\"family\",\"base\"], how = 'outer')\n",
    "        dfaux[\"nr_appearances\"] = dfaux[\"nr_appearances\"].fillna(0)\n",
    "        dfaux[\"nr_appearances_old\"] = dfaux[\"nr_appearances_old\"].fillna(0)\n",
    "        dfaux[\"nr_app_tot\"] = dfaux[\"nr_appearances\"]+dfaux[\"nr_appearances_old\"]\n",
    "        dfaux[\"highlight\"]=(dfaux[\"highlighted\"]==False)&((dfaux[\"nr_app_tot\"]>30)|((dfaux[\"freq_text\"]>0.01)&(dfaux[\"nr_appearances\"]>5)))\n",
    "        if (dfaux[\"highlight\"].sum()<10):\n",
    "            highlight = dfaux[(dfaux[\"highlight\"]==False)&(dfaux[\"highlighted\"]==False)].sort_values(\"freq_corpus\",ascending=False).iloc[:10-dfaux[\"highlight\"].sum()][[\"family\",\"base\"]].drop_duplicates()\n",
    "            tohighlight = list(highlight[\"family\"]+\"_\"+highlight[\"base\"])\n",
    "            dfaux[\"highlight\"] = dfaux[\"highlight\"]|dfaux.apply(lambda x: x[\"family\"]+\"_\"+x[\"base\"] in tohighlight, axis = 1)\n",
    "        pd.merge(dfvocab,dfaux[dfaux[\"highlight\"]])[\"token\"].apply(isanewword)\n",
    "        dfaux[\"nr_appearances\"] = dfaux[\"nr_app_tot\"]\n",
    "        dfaux[\"freq_corpus\"] = dfaux.apply(lambda x: max([x[\"freq_corpus_old\"],x[\"freq_corpus\"]]),axis = 1)\n",
    "        dfaux[\"highlighted\"] = dfaux[\"highlighted\"]|dfaux[\"highlight\"]\n",
    "        dfaux=dfaux[[\"family\",\"base\",\"nr_appearances\",\"freq_corpus\",\"highlighted\"]]\n",
    "        dfaux.to_csv(\"history.csv\",sep=\"|\")\n",
    "        \n",
    "        profile.iloc[0,0]=profile.iloc[0,0]+1\n",
    "        profile.iloc[1,0]=profile.iloc[1,0]+nr_words\n",
    "        profile.to_csv(\"profile.csv\",sep=\"|\")\n",
    "    except:\n",
    "        dfvocab = pd.Series(doc).apply(basewordfreq).apply(pd.Series)\n",
    "        nr_words = len(dfvocab.dropna())\n",
    "        dfvocab = dfvocab.explode(2)\n",
    "        dfvocab.columns = [\"token\", \"family\", \"base\", \"freq\"]\n",
    "        dfaux = dfvocab.groupby([\"family\", \"base\"]).agg({\"freq\":[\"count\",\"max\"]})\n",
    "        dfaux.columns = [\"nr_appearances\", \"freq_corpus\"]\n",
    "        dfaux=dfaux.reset_index()\n",
    "        dfaux[\"freq_text\"]=dfaux[\"nr_appearances\"]/nr_words\n",
    "        dfaux[\"highlight\"]=(dfaux[\"freq_corpus\"]>0.01)|((dfaux[\"freq_text\"]>0.01)&(dfaux[\"nr_appearances\"]>5))\n",
    "        if (dfaux[\"highlight\"].sum()<10):\n",
    "            highlight = dfaux[dfaux[\"highlight\"]==False].sort_values(\"freq_corpus\",ascending=False).iloc[:10-dfaux[\"highlight\"].sum()][[\"family\",\"base\"]].drop_duplicates()\n",
    "            tohighlight = list(highlight[\"family\"]+\"_\"+highlight[\"base\"])\n",
    "            dfaux[\"highlight\"] = dfaux[\"highlight\"]|dfaux.apply(lambda x: x[\"family\"]+\"_\"+x[\"base\"] in tohighlight, axis =1)\n",
    "        pd.merge(dfvocab,dfaux[dfaux[\"highlight\"]])[\"token\"].apply(isanewword)\n",
    "        dfaux=dfaux[[\"family\",\"base\",\"nr_appearances\",\"freq_corpus\",\"highlight\"]]\n",
    "        dfaux.columns = [\"family\",\"base\",\"nr_appearances\",\"freq_corpus\",\"highlighted\"]\n",
    "        dfaux.to_csv(\"history.csv\",sep=\"|\")\n",
    "        pd.Series([1, nr_words]).to_csv(\"profile.csv\",sep=\"|\")\n",
    "        \n",
    "        \n",
    "##################################\n",
    "## FORMAT\n",
    "##################################\n",
    "\n",
    "def formattokensSNSV(x):\n",
    "    attributes = x._.att_li\n",
    "    formatted = x.text\n",
    "    formatted_v = x.text\n",
    "    if attributes[\"family\"]==\"VERB\":\n",
    "        formatted=\"<b>{}</b>\".format(formatted)\n",
    "        formatted_v=\"<b>{}</b>\".format(formatted_v)\n",
    "        if \"Fin\" in attributes[\"aux_labels\"]:\n",
    "            formatted_v ='<span style=\"color: blue\">{}</span>'.format(formatted_v)\n",
    "        if \"Part\" in attributes[\"aux_labels\"]:\n",
    "            formatted_v ='<span style=\"color: pink\">{}</span>'.format(formatted_v)\n",
    "        if \"Inf\" in attributes[\"aux_labels\"]:\n",
    "            formatted_v ='<span style=\"color: orange\">{}</span>'.format(formatted_v)\n",
    "        if \"Sub\" in attributes[\"aux_labels\"]:\n",
    "            formatted_v = '<span class=\"wavyUnderline\">{}</span>'.format(formatted_v)\n",
    "        if \"Ind\" in attributes[\"aux_labels\"]:\n",
    "            #formatted_v = '<span class=\"normalUnderline\">{}</span>'.format(formatted_v)\n",
    "            pass\n",
    "        if \"Pres\" in attributes[\"aux_labels\"]:\n",
    "            pass\n",
    "            #formatted_v = '<span class=\"normalOverline\">{}</span>'.format(formatted_v)\n",
    "        if \"Past\" in attributes[\"aux_labels\"]:\n",
    "            formatted_v = '<i>{}</i>'.format(formatted_v)\n",
    "    elif x._.att_li[\"family\"] == \"NOUN\": #prima cera un else e basta\n",
    "        #formatted_v = \"<b>{}</b>\".format(formatted_v)\n",
    "        if \"Nom\" in attributes[\"aux_labels\"]:\n",
    "            formatted = '<span class=\"doubleUnderline\">{}</span>'.format(formatted)\n",
    "            formatted_v = formatted\n",
    "        if \"Acc\" in attributes[\"aux_labels\"]:\n",
    "            formatted = '<span class=\"normalUnderline\">{}</span>'.format(formatted)\n",
    "            formatted_v = formatted\n",
    "        if \"Dat\" in attributes[\"aux_labels\"]:\n",
    "            formatted = '<span class=\"dashedUnderline\">{}</span>'.format(formatted)\n",
    "            formatted_v = formatted\n",
    "        if \"Gen\" in attributes[\"aux_labels\"]:\n",
    "            formatted = '<span class=\"dottedUnderline\">{}</span>'.format(formatted)\n",
    "\n",
    "        if \"Masc\" in attributes[\"aux_labels\"]:\n",
    "            formatted ='<span style=\"color: blue\">{}</span>'.format(formatted)\n",
    "        if \"Fem\" in attributes[\"aux_labels\"]:\n",
    "            formatted ='<span style=\"color: pink\">{}</span>'.format(formatted)\n",
    "        if \"Neut\" in attributes[\"aux_labels\"]:\n",
    "            formatted ='<span style=\"color: orange\">{}</span>'.format(formatted)\n",
    "            \n",
    "        if \"Plur\" in attributes[\"aux_labels\"]:\n",
    "            formatted ='<span class=\"doubleOverline\">{}</span>'.format(formatted)\n",
    "            if (\"Nom\" in attributes[\"aux_labels\"]) or (\"Dat\" in attributes[\"aux_labels\"]) or (\"Acc\" in attributes[\"aux_labels\"]):\n",
    "                formatted_v = '<span class=\"doubleOverline\">{}</span>'.format(formatted_v)\n",
    "        if \"Sing\" in attributes[\"aux_labels\"]:\n",
    "            formatted ='<span class=\"normalOverline\">{}</span>'.format(formatted)\n",
    "            #formatted_v = '<span class=\"normalOverline\">{}</span>'.format(formatted_v)\n",
    "    formatted_new = x.text\n",
    "    if x._.newword:\n",
    "        formatted_new = \"<b>{}</b>\".format(formatted_new)\n",
    "\n",
    "\n",
    "    x._.html_formatted_SN= formatted\n",
    "    x._.html_formatted_SV= formatted_v\n",
    "    x._.html_formatted_new= formatted_new\n",
    "\n",
    "def computeformat(doc):\n",
    "    for i in doc:\n",
    "        formattokensSNSV(i)\n",
    "        \n",
    "def replacequestion(doc,qcat,qcatno=\"\"): #aggiungere una probabilità di sostituire oppure no.\n",
    "    string = \"\"\n",
    "    wordlist = []\n",
    "    for i in doc:\n",
    "        if i.is_punct == True:\n",
    "            string+=i.text\n",
    "        else:\n",
    "            if i.is_alpha and (qcat in i._.questioncategory) and (qcatno not in i._.questioncategory):\n",
    "                string+= \" ________ \"\n",
    "                wordlist.append(i.text.lower())\n",
    "            else:\n",
    "                string+= \" \"+i.text\n",
    "    random.shuffle(wordlist)\n",
    "\n",
    "    string += \"\"\"\n",
    "\n",
    "    You should use the words in the following list:\n",
    "\n",
    "    \"\"\" + str(wordlist)\n",
    "    return string\n",
    "\n",
    "def printFormattedText(doc):\n",
    "    initialstring = \"\"\n",
    "    css = \"\"\"\n",
    "    /* css here */\n",
    "\n",
    "{\n",
    "  border: 1px dotted black;\n",
    "}\n",
    "\n",
    "p.question {\n",
    "  font-family: Arial, sans-serif;\n",
    "  font-size:20px;\n",
    "  color: #2E2E2E;\n",
    "  margin-bottom:0px;\n",
    "}\n",
    "\n",
    "h2.quizHeader {\n",
    "  font-family: Arial, sans-serif;\n",
    "  font-weight:normal;\n",
    "  font-size:25px;\n",
    "  line-height: 27px;\n",
    "  margin: 24px 0 12px 0;\n",
    "  padding: 0 0 4px 0;\n",
    "  border-bottom: 1px solid #a2a2a2;\n",
    "}\n",
    "\n",
    "h2.quizScore{\n",
    "  font-family: Arial, sans-serif;\n",
    "  font-size:25px;\n",
    "}\n",
    "\n",
    "div.quizAnswers{\n",
    "  font-family: Arial, sans-serif;\n",
    "  font-size:16px;\n",
    "  color: #424242;\n",
    "  padding: 4px 0 4px 0;\n",
    "}\n",
    "\n",
    "label {\n",
    "  font-family: Arial, sans-serif;\n",
    "  font-size:14px;\n",
    "  color: #424242;\n",
    "  vertical-align:top;\n",
    "}\n",
    "\n",
    "input.answer[type=\"radio\"] {\n",
    "  margin-bottom: 10px;\n",
    "}\n",
    "\n",
    "input.quizSubmit[type=\"submit\"] {\n",
    "  -webkit-background-clip: border-box;\n",
    "  -webkit-background-origin: padding-box;\n",
    "  -webkit-background-size: auto;\n",
    "  -webkit-transition-delay: 0s, 0s;\n",
    "  -webkit-transition-duration: 0.2s, 0.2s;\n",
    "  -webkit-transition-property: color, background-color;\n",
    "  -webkit-transition-timing-function: ease, ease;\n",
    "  box-shadow: rgba(0, 0, 0, 0.498039) 0px 0px 5px 0px;\n",
    "  color: #ffffff;\n",
    "  background-color: #c30b0a;\n",
    "  margin: 0;\n",
    "  border: 0;\n",
    "  outline: 0;\n",
    "  text-transform:uppercase;\n",
    "  height:35px;\n",
    "  width:85px;\n",
    "  border: 1px solid #5E5E5E;\n",
    "  border-radius:5px;\n",
    "\n",
    " }\n",
    "\n",
    "input.quizSubmit[type=\"submit\"]:hover {\n",
    "  color: #ffffff;\n",
    "  background: #680f11;\n",
    "  text-decoration: none;\n",
    "}\n",
    "\n",
    "table {\n",
    "  background-color: #F2F2F2;\n",
    "  border:1px solid #BDBDBD;\n",
    "  border-radius:5px;\n",
    "  padding:10px;\n",
    "  padding-left:25px;\n",
    "  box-shadow: rgba(0, 0, 0, 0.498039) 0px 0px 1px 0px;\n",
    "}\n",
    "\n",
    "th {\n",
    "\n",
    "}\n",
    "\n",
    "tr {\n",
    "\n",
    "}\n",
    "\n",
    "td {\n",
    "\n",
    "}\n",
    "\n",
    ".submitter {\n",
    "\t  width:85px;\n",
    "}\n",
    "\n",
    ".hide {\n",
    "\t  display:none;\n",
    "}\n",
    ".normalUnderline {\n",
    "    text-decoration:underline #000;\n",
    "}\n",
    "\n",
    ".normalOverline {\n",
    "    text-decoration: overline 1px #000;\n",
    "}\n",
    "\n",
    ".wavyUnderline {\n",
    "    text-decoration:underline wavy #000;\n",
    "}\n",
    "\n",
    ".wavyOverline {\n",
    "    text-decoration: overline wavy 1px #000;\n",
    "}\n",
    "\n",
    ".doubleOverline {\n",
    "    text-decoration: overline 1px double #000;\n",
    "}\n",
    "\n",
    ".doubleUnderline {\n",
    "    text-decoration:underline #000;\n",
    "    border-bottom: 1px solid #000;\n",
    "}\n",
    "\n",
    ".dottedUnderline {\n",
    "    border-bottom: 1px dotted #000;\n",
    "    text-decoration: none;\n",
    "}\n",
    "\n",
    ".dashedUnderline {\n",
    "    border-bottom: 1px dashed #000;\n",
    "    text-decoration: none;\n",
    "}\n",
    "/*SFS light red = #c30b0a;\n",
    "SFS dark red = #9f2026; */\n",
    "\n",
    "    \"\"\"\n",
    "    initialstring_v = \"\"\n",
    "    initialstring_new = \"\"\n",
    "    initialstring_qsvp = replacequestion(doc,\"SVP\")\n",
    "    initialstring_qnew = replacequestion(doc,\"NEW\")\n",
    "    initialstring_qadp = replacequestion(doc,\"ADP\")\n",
    "    initialstring_qoth = replacequestion(doc,\"OTHERS\",\"ADP\")\n",
    "\n",
    "        \n",
    "                \n",
    "    \n",
    "    html = '''<!DOCTYPE html><html lang=\"en\"><head><style>{}</style></head><body><p style=\"line-height: 200%\">{}</p></body></html>'''\n",
    "\n",
    "    for i in doc:\n",
    "        if i.is_punct==True:\n",
    "            initialstring+=i._.html_formatted_SN\n",
    "            initialstring_v += i._.html_formatted_SV\n",
    "            initialstring_new += i._.html_formatted_new\n",
    "        else:\n",
    "            initialstring+= \" \"+ i._.html_formatted_SN\n",
    "            initialstring_v +=\" \"+ i._.html_formatted_SV\n",
    "            initialstring_new += \" \"+ i._.html_formatted_new\n",
    "\n",
    "\n",
    "\n",
    "    final,final_t = gettranslatednumbered(doc.text)\n",
    "    html3 = html.format(css,numberparagraphs(initialstring))\n",
    "    html4 = html.format(css,numberparagraphs(initialstring_v))\n",
    "    html5 = html.format(css,numberparagraphs(initialstring_new))\n",
    "    html6 = html.format(css,numberparagraphs(initialstring_qsvp))\n",
    "    html7 = html.format(css,numberparagraphs(initialstring_qnew))\n",
    "    html8 = html.format(css,numberparagraphs(initialstring_qadp))\n",
    "    html9 = html.format(css,numberparagraphs(initialstring_qoth))\n",
    "    html1 = html.format(css,final)\n",
    "    html2 = html.format(css,final_t)\n",
    "    return [html1, html2, html3, html4, html5, html6,html7,html8, html9]\n",
    "        \n",
    "        \n",
    "##################################\n",
    "## PIPELINE\n",
    "##################################\n",
    "\n",
    "\n",
    "def pipeline(folder, file, questions = False):\n",
    "    print(\"1\")\n",
    "    Token.set_extension('att_li', default={\"family\":\"\",\"subtype\":\"\",\"aux_labels\":[],\"aux_string\":\"\"},force=True)\n",
    "    #Token.set_extension('svp', default=\"\",force=True)\n",
    "    Token.set_extension(\"html_formatted_SN\", default=\"\",force=True)\n",
    "    Token.set_extension(\"html_formatted_SV\", default=\"\",force=True)\n",
    "    Token.set_extension(\"html_formatted_new\", default=\"\",force=True)\n",
    "    Token.set_extension(\"questioncategory\",default=[],force=True)\n",
    "    Token.set_extension(\"newword\",default=False,force=True)\n",
    "    nlp = spacy.load(\"de_core_news_lg\")\n",
    "    print(\"2\")\n",
    "\n",
    "    f = codecs.open(folder+\"/\"+file, \"r\", \"utf-8\")    # suess_sweet.txt file contains two\n",
    "    text = f.read()                          # comma-separated words: süß, sweet\n",
    "    f.close()\n",
    "\n",
    "    doc = nlp(text)\n",
    "    assert doc.has_annotation(\"SENT_START\")\n",
    "    computeattli(doc)\n",
    "    computeformat(doc)\n",
    "    return printFormattedText(doc)\n",
    "\n",
    "\n",
    "def pipeline2(text, folder = \"Templates\"):\n",
    "    global doc\n",
    "    print(\"1\")\n",
    "    Token.set_extension('att_li', default={\"family\":\"\",\"subtype\":\"\",\"aux_labels\":[],\"aux_string\":\"\"},force=True)\n",
    "    #Token.set_extension('svp', default=\"\",force=True)\n",
    "    Token.set_extension(\"html_formatted_SN\", default=\"\",force=True)\n",
    "    Token.set_extension(\"html_formatted_SV\", default=\"\",force=True)\n",
    "    Token.set_extension(\"html_formatted_new\", default=\"\",force=True)\n",
    "    Token.set_extension(\"questioncategory\",default=\"\",force=True)\n",
    "    Token.set_extension(\"newword\",default=False,force=True)\n",
    "    nlp = spacy.load(\"de_core_news_lg\")\n",
    "    print(\"2\")\n",
    "\n",
    "    doc = nlp(text)\n",
    "    assert doc.has_annotation(\"SENT_START\")\n",
    "    computeattli(doc)\n",
    "    \n",
    "    processvocabulary(doc)\n",
    "    computeformat(doc)\n",
    "    htmls =  printFormattedText(doc)\n",
    "    \n",
    "    fw = open(\"original.html\", \"w\")\n",
    "    fw.write(htmls[0])\n",
    "    fw.close()\n",
    "    \n",
    "    fw = open(\"translation.html\", \"w\")\n",
    "    fw.write(htmls[1])\n",
    "    fw.close()\n",
    "    \n",
    "    fw = open(\"SN.html\", \"w\")\n",
    "    fw.write(htmls[2])\n",
    "    fw.close()\n",
    "    \n",
    "    fw = open(\"SV.html\", \"w\")\n",
    "    fw.write(htmls[3])\n",
    "    fw.close()\n",
    "\n",
    "    fw = open(\"newwords.html\", \"w\")\n",
    "    fw.write(htmls[4])\n",
    "    fw.close()\n",
    "    \n",
    "    fw = open(\"qsvp.html\", \"w\")\n",
    "    fw.write(htmls[5])\n",
    "    fw.close()\n",
    "    \n",
    "    fw = open(\"qnew.html\", \"w\")\n",
    "    fw.write(htmls[6])\n",
    "    fw.close()    \n",
    "    fw = open(\"qadp.html\", \"w\")\n",
    "    fw.write(htmls[7])\n",
    "    fw.close()    \n",
    "    fw = open(\"qoth.html\", \"w\")\n",
    "    fw.write(htmls[8])\n",
    "    fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "UN sehen Kriegsverbrechen durch Taliban\n",
    "Die radikalislamischen Taliban begehen in Afghanistan nach UN-Informationen schwere Menschenrechtsverletzungen. Betroffen seien vor allem Frauen und Journalisten, erklärte UN-Generalsekretär Guterres.\n",
    "Der Generalsekretär der Vereinten Nationen, António Guterres, betonte, es sei \"besonders entsetzlich und herzzerreißend, Berichte zu sehen, wonach den afghanischen Mädchen und Frauen ihre hart erkämpften Rechte entrissen werden\". Und er betonte: \"Angriffe auf Zivilisten sind eine schwere Verletzung des humanitären Völkerrechts und sind gleichbedeutend mit Kriegsverbrechen.\"\n",
    "\n",
    "Provinzstädte fallen wie Dominosteine\n",
    "Seit Beginn des Abzugs der NATO-Truppen aus Afghanistan haben die radikalislamischen Taliban weite Teile des Landes unter ihre Kontrolle gebracht. In den vergangenen acht Tagen nahmen die Islamisten rund die Hälfte der 34 afghanischen Provinzhauptstädte ein. Am Freitag standen sie nach der Eroberung der Provinzhauptstadt Pul-i-Alam nur noch 50 Kilometer vor der Hauptstadt Kabul, wie ein Regionalabgeordneter der Provinz Logar mitteilte.\n",
    "\n",
    "Taliban attackieren Masar-i-Scharif\n",
    "Inzwischen haben die islamistischen Kämpfer auch einen Angriff auf die nördliche Stadt Masar-i-Scharif gestartet. Laut Munir Ahmad Farhad, Sprecher des Gouverneurs in der Provinz Balch, attackieren die Taliban die Stadt aus mehreren Richtungen. Es sei zu schweren Kämpfen in den Außenbezirken gekommen. Über Opferzahlen ist bisher nichts bekannt. In Masar-i-Scharif befand sich bis zum Ende des Afghanistan-Einsatzes das zentrale Feldlager der dort eingesetzten Bundeswehrsoldaten.\n",
    "\n",
    "Die Taliban hatten während ihrer Herrschaft von 1996 bis 2001 eine strenge Auslegung des islamischen Rechts in Afghanistan eingeführt. Mädchen waren von Bildung, Frauen vom Arbeitsleben ausgeschlossen. Straftaten wurden mit öffentlichen Auspeitschungen oder Hinrichtungen geahndet.\n",
    "\n",
    "Soll Kabul abgeschnitten werden?\n",
    "Nach Ansicht des US-Verteidigungsministeriums versuchen die Taliban, Kabul vom Rest des Landes abzuschneiden. Die afghanische Hauptstadt sei momentan aber nicht \"unmittelbar bedroht\", sagte der Sprecher des Pentagons, John Kirby.\n",
    "\n",
    "Er warf zugleich der afghanischen Führung und den Sicherheitskräften mangelnde Kampfbereitschaft vor. Es sei \"beunruhigend\" zu sehen, dass die politische und militärische Führung nicht den\n",
    "Willen gehabt habe, sich dem Vormarsch der militanten Islamisten zu widersetzen. Die USA hätten diesen \"fehlenden Widerstand\" durch die afghanischen Streitkräfte nicht vorhersehen können. Mit Blick auf die finanzielle Unterstützung der US-Regierung fügte Kirby hinzu: \"Geld kann keinen Willen kaufen.\"\n",
    "\n",
    "Die USA sehen sich damit in dem Land am Hindukusch zunehmend auf sich selbst gestellt. Sie wollen auch deshalb 3000 zusätzliche Soldatinnen und Soldaten an den Flughafen in Kabul verlegen. Sie sollen unter anderem die Reduzierung des Personals der US-Botschaft unterstützen. Zudem verlegen die USA bis zu 4000 weitere Soldaten nach Kuwait und noch einmal rund 1000 nach Katar, um im Bedarfsfall als Verstärkung bereitzustehen. Der Abzug der US-Soldaten aus Afghanistan soll aber weiterhin bis zum 31. August abgeschlossen werden.\n",
    "\n",
    "Seehofer macht Zugeständnisse\n",
    "Bundesinnenminister Horst Seehofer kündigte an, er wolle die Einreise afghanischer Ortskräfte erleichtern und ihre Identität notfalls erst auf deutschem Boden überprüfen lassen. \"Wenn die Klärung der Identität und die Erteilung der Visa in Afghanistan nicht möglich ist, kann sie in Deutschland durchgeführt werden\", sagte der CSU-Politiker der \"Süddeutschen Zeitung\". Seehofer weiter: \"Wir sind für jedes Verfahren offen. Am Bundesinnenministerium scheitert keine Einreise von Ortskräften.\"\n",
    "\n",
    "Außenminister Heiko Maas (SPD) hatte als Konsequenz auf den Vormarsch der militant-islamistischen Taliban in Afghanistan eine Reduzierung des Botschaftspersonals in Kabul auf das \"absolute Minimum\" angekündigt. Für die Rückholaktion sollen zwei Flugzeuge gechartert werden, mit denen dann auch afghanische Ortskräfte nach Deutschland gebracht werden sollen, die für die Bundeswehr oder Bundesministerien tätig waren oder es noch sind.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "pipeline2(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"\"\"\n",
    "Die deutsche Direktheit\n",
    "Bei der deutschen Direktheit handelt es sich um ein bereits bekanntes Phänomen. Diejenigen, die sie nicht kennen, sind zunächst überrascht, wenn nicht sogar schockiert von der direkten Art. Unterschiedliche Nationen nehmen sie auf ganz verschiedene Art und Weise wahr.\n",
    "\n",
    "Ein Brasilianer berichtet davon, wie er das erste Mal in einem deutschen Supermarkt einkaufen war. Er erledigte gemütlich seine Einkäufe und legte sie anschließend in seinem Tempo auf das Kassenband. Die Reaktion der Kassiererin war daraufhin, dass sie ihm sagte, er sollte jetzt mal bitte schneller machen.  \n",
    "\n",
    "\n",
    "Aussagen wie: „Guten Tag zusammen. Wir sollten schnell mit den Verhandlungen beginnen! Ich habe folgenden Vorschlag, sind Sie mit mir einer Meinung…?“ (Frankfurter Rundschau: 2016), empfinden Japaner/-innen als sehr unhöflich, zu Beginn einer Geschäftsverhandlung. Sowas kann eine potenzielle Geschäftsbeziehung kaputt machen.   \n",
    "\n",
    "\n",
    "Ein Amerikaner erzählt davon, wie er an der Universität ein Seminar besucht hat, welches von einem deutschen und einem amerikanischen Dozenten gehalten wurde. Während des Seminars hat einer der Teilnehmer immer wieder Fragen gestellt und damit den Zeitplan des Seminars durcheinandergebracht. Die Reaktion des amerikanischen Dozenten darauf war, dass er den Vorschlag äußerte, die Fragen doch bitte am Ende des Seminars zu stellen. Der deutsche Dozent unterbrach ihn und sagte, er solle doch jetzt ruhig sein, er nerve sie alle.  \n",
    "\n",
    "\n",
    "Jedoch ist diese Direktheit in keiner Art und Weise unhöflich gemeint. Für Menschen, die in Deutschland aufgewachsen sind, bedeutet Direktheit, dass man aufrichtig und ehrlich ist, da man ein mögliches Problem sofort anspricht. Die Kommunikation dient zum Übermitteln von Informationen. Bei der Kommunikation steht die Sachlichkeit, also der tatsächliche Informationsaustausch, mehr im Vordergrund, da dadurch schneller und effizienter gehandelt werden kann. Im Fokus der Kommunikation steht nicht das „wie“, sondern viel mehr das „was“. Das Motto lautet: Wie komme ich so effizient wie möglich an mein Ziel? \n",
    "\n",
    "\n",
    "Durch den Prozess der Industrialisierung und dem wirtschaftlichen Aufschwung, der nach 1945 stattgefunden hat, ist das Bewusstsein für effizientes Arbeiten entstanden. Man behebt am schnellsten Probleme, indem man sie direkt anspricht. Aus diesem Grund hat sich die direkte Kommunikation durchgesetzt. Effizientes Arbeiten bedeutet, dass Probleme direkt erkannt und gelöst werden.  \n",
    "\n",
    "\n",
    "Zu der Direktheit gehört auch das Äußern von Kritik. In der deutschen Berufswelt ist konstruktive Kritik sehr angesehen, denn es gibt immer etwas zu verbessern. Äußert jemand direkt Kritik, wird das nicht als negativ gewertet, sondern als Verbesserungsmöglichkeit, welche man sich in Ruhe anhören kann und dann entscheiden kann, inwieweit man die Kritik sinnvoll findet und annehmen möchte. Wichtig dabei ist jedoch, dass darauf geachtet wird, wie Kritik geäußert wird. Es macht einen Unterschied, ob gesagt wird, dass jemand seine Arbeit schlecht macht oder ob geäußert wird, dass man das Layout des Firmennamens gerne etwas auffälliger gestaltet hätte. Verbesserungsvorschläge sind jederzeit zu gebrauchen und können wirklich hilfreich sein.  \n",
    "\n",
    "\n",
    "Ein weiterer Aspekt der deutschen Kommunikation, der oft als zu direkt, wenn nicht sogar schon als beleidigend wahrgenommen wird, ist „Nein“ zu sagen. Es ist völlig normal, wenn man eine Person fragt, ob sie Lust hat, wandern zu gehen, dass die Person dann antwortet: „Nein, ich gehe nicht gerne wandern“. Dies ist in keiner Weise unhöflich gemeint. Es wurde ein Vorschlag gemacht und dieser kann angenommen oder abgelehnt werden. Dazu eignen sich „Ja“ und „Nein“. Ein „Nein“ bedeutet auch wirklich „Nein“ und ist keine Aufforderung dazu nochmal gefragt zu werden. \n",
    "\n",
    "\n",
    "Von vielen anderen Nationalitäten wird diese offensichtliche Verneinung als beleidigend wahrgenommen. In Brasilien zum Beispiel wird das Wort „Nein“ so gut wie gar nicht gebraucht, da es als sehr unhöflich wahrgenommen wird. Ist man zum Beispiel bei einer brasilianischen Familie zum Essen eingeladen und wird gefragt, ob man gerne Fisch isst, obwohl man keinen Fisch mag, sollte man nicht sagen, dass man keinen Fisch mag. Stattdessen würde man so etwas sagen, wie: „Ich esse Fisch normalerweise nicht, aber dieser ist sehr lecker.“ Damit wird vermieden, das Wort „Nein“ zu benutzen, um niemanden vor den Kopf zu stoßen. \n",
    "\n",
    "\n",
    "Solche Regeln in der Kommunikation können oft zu Missverständnissen führen, wenn die Regeln den betreffenden Personen nicht bekannt sind. Wichtig ist im Hinterkopf zu behalten, dass oftmals keine böse Absicht dahintersteckt. Elena, eine Britin, die einige Jahre in Deutschland gelebt hat, berichtet dem Spiegel 2017, dass sie die deutsche Direktheit vermisst, denn die Deutschen sagen einfach, was sie denken. Direktheit kann auch sehr praktisch sein, wenn man sich daran gewöhnt hat.  \n",
    "\n",
    "\n",
    "Ist dir schon einmal ein derartige Situation in Deutschland passiert und wenn ja, wie bist du damit umgegangen?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "text2 = \"\"\"\n",
    "Persönlichkeitsunterschiede im Job\n",
    "Introvertierte und Extrovertierte – manchmal scheinen sie wie zwei völlig verschiedene Spezies. Die einen ruhig und nachdenklich, die anderen redefreudig und impulsiv. Kein Wunder, dass es da auch am Arbeitsplatz hin und wieder zu Schwierigkeiten kommen kann. Doch diese lassen sich mit ein wenig Empathie beheben.\n",
    "\n",
    "Wer kennt sie nicht? Die energiegeladene Kollegin, die den ganzen Tag reden könnte oder den reservierten Kollegen, der so gut wie nie etwas von sich preisgibt. Und mindestens eines davon hat jeden bestimmt schon einmal genervt. Dies ist wahrscheinlich in den unterschiedlichen Persönlichkeiten begründet bzw. darin, dass eine/r zu den Extrovertierten und der/die andere zu den Introvertierten gehört. \n",
    "\n",
    "\n",
    "Der Schweizer Psychoanalytiker Carl Gustav Jung führte diese Begriffe erstmals im Jahr 1921 ein. Extrovertierte werden dabei dadurch charakterisiert, dass sie viel Stimulation aus ihrer externen Umgebung benötigen und diese vor allem aus der Interaktion mit ihren Mitmenschen sowie aufregenden Aktivitäten ziehen. Introvertierte hingegen benötigen weitaus weniger dieser externen Stimulation und ziehen ihre Energie aus eher ruhigeren Umgebungen sowie der Auseinandersetzung mit ihren eigenen Gedanken und Gefühlen. \n",
    "\n",
    "\n",
    "Dies ist nicht nur psychologisch begründet, sondern auch neurobiologisch. Das Belohnungssystem des Gehirns ist bei Extrovertierten aktiver, was dazu führt, dass externe Stimulationen und die Aussicht auf Belohnungen die Produktion des Neurotransmitters Dopamin anregen, wodurch sich Extrovertierte energiegeladen und motiviert fühlen. Diese Dopamin-Produktion ist bei Introvertierten durch dieselben Aktivitäten deutlich geringer und Wohlbefinden stellt sich bei ihnen vielmehr durch die Produktion des Neurotransmitters Acetylcholin ein, welches vor allem durch Ruhe und Zeit alleine entsteht. \n",
    "\n",
    "\n",
    "Das bedeutet jedoch nicht, dass Introvertierte isolierte, ungesellige Alleingänger sind und auch Schüchternheit ist nicht gleichzusetzen mit Introversion. Das Sozialverhalten und der Kommunikationsstil sind schlichtweg anders als bei Extrovertierten. Aber wie genau können Intro- und Extrovertierte dann konkret erfolgreich kommunizieren und zusammenarbeiten? Die folgenden Tipps können dabei helfen.\n",
    "\n",
    "\n",
    "Arbeiten und Kommunizieren mit Introvertierten:\n",
    "\n",
    "\n",
    "1) Introvertierte bevorzugen die Gesellschaft kleiner Gruppen und/oder vertrauter Personen. Führungskräften wird daher empfohlen, Meetings in möglichst kleinen Runden abzuhalten und Aufgaben, welche häufige Kontakte mit (vielen) unbekannten Personen involvieren eher Extrovertierten zu überlassen. \n",
    "\n",
    "\n",
    "2) Planung und Vorbereitung sind Introvertierten sehr wichtig. Jegliche Vorankündigungen wie beispielsweise das Zusenden der Tagesordnung vor einem Meeting ermöglichen ihnen, sich ausreichend vorzubereiten und dadurch letztendlich auch mehr zu einem Thema beitragen zu können.\n",
    "\n",
    "\n",
    "3) Eng damit verbunden ist auch die Präferenz der schriftlichen Kommunikation. Introvertierte werden Kollegen und Geschäftspartnern daher eher eine E-Mail schreiben anstatt sie anzurufen und werden es zu schätzen wissen, wenn sich Extrovertierte ebenfalls zumindest schriftlich ankündigen, bevor sie zum Hörer greifen oder persönlich bei ihnen vorbeischauen. \n",
    "\n",
    "\n",
    "4) Introvertierte werden in Meetings eher selten das Wort ergreifen oder spontan ihre Meinung äußern. Das heißt allerdings nicht, dass sie keine Meinung haben. Sie sollten daher gezielt angesprochen werden, am besten nach dem Meeting, wenn sie die Gelegenheit hatten, das Gehörte zu verarbeiten und ihre Gedanken diesbezüglich zu sortieren. \n",
    "\n",
    "\n",
    "5) Introvertierte brauchen Zeit, um ihre Kollegen kennenzulernen. Vertrauen aufzubauen dauert bei ihnen zwar vielleicht länger, sie sind deshalb jedoch nicht unnahbar oder desinteressiert an Gesprächen bzw. einem Kontaktaufbau.\n",
    "\n",
    "\n",
    "6) Extrovertierte sollten im Hinterkopf behalten, dass Introvertierte Ruhe benötigen, um ihre Energiespeicher aufzufüllen und konzentriert arbeiten zu können. Darum sollte ihnen auch hin und wieder Zeit für sich gelassen werden.\n",
    "\n",
    "\n",
    "7) Introvertierte ziehen tiefe Gespräche Small Talk vor. Eine Verbindung zu ihnen baut man daher am besten und schnellsten über Themen auf, für die sie sich begeistern und zu denen sie viel beitragen können. Dann können auch Introvertierte überraschend redefreudig sein.  \n",
    "\n",
    "\n",
    "8) Introvertierten Mitarbeitenden sollten, sofern möglich, geräuschärmere Bereiche oder eigene Büros zum Arbeiten zur Verfügung gestellt werden. Auch Home-Office ist eine gute Möglichkeit, ihnen die ruhige Arbeitsumgebung zu bieten, die sie für eine möglichst hohe Produktivität und Konzentration benötigen.  \n",
    "\n",
    "\n",
    "Arbeiten und Kommunizieren mit Extrovertierten:\n",
    "\n",
    "\n",
    "1) Es empfiehlt sich, Small Talk zu trainieren. Dieser sollte als Möglichkeit gesehen werden, mehr über die extrovertierten Kollegen zu erfahren und so auf Themen zu kommen, bei denen man später mehr in die Tiefe gehen kann. Introvertierte können sich beispielsweise im Voraus ein paar Dinge aus ihrem privaten Leben überlegen, die sie mit ihren extrovertierten Kollegen teilen könnten, ohne dass sie sich dabei unwohl fühlen. So können sie ihnen die Chance geben, sie näher kennenzulernen und Vertrauen aufzubauen. \n",
    "\n",
    "\n",
    "2) Führungskräfte sollten Extrovertierten bevorzugt abwechslungsreiche Aufgaben geben, welche Kontakte mit vielen unterschiedlichen Personen beinhalten, mit denen sie sich austauschen und gemeinsam Lösungen erarbeiten können. So bleiben sie motiviert und es wird ihnen garantiert nicht langweilig.\n",
    "\n",
    "\n",
    "3) Extrovertierte äußern gerne spontan ihre Gedanken und tauschen Ideen aus. Introvertierte sollten sich vor allem bei Meetings und Konferenzen darauf vorbereiten und, falls möglich, ein paar inhaltliche Argumente im Voraus zurechtlegen. In jedem Fall hilft es, den Extrovertierten vertiefende Folgefragen zu stellen, damit man spontane Gedanken gemeinsam ausarbeiten und voneinander profitieren kann.\n",
    "\n",
    "\n",
    "4) Es sollte stets im Hinterkopf behalten werden, dass Extrovertierte ihre Energie und Motivation aus der Interaktion mit anderen ziehen. Man sollte ihnen also auch Raum zum Reden geben und es als Introvertierte nicht persönlich nehmen, wenn man hin und wieder bei einem Gespräch unterbrochen wird. Führungskräfte sollten dennoch darauf achten, dass introvertierte Mitarbeitende dadurch nicht untergehen und beispielsweise in Meetings entsprechend moderieren. \n",
    "\n",
    "\n",
    "5) Es wird davon abgeraten, extrovertierten Kollegen lange, detaillierte E-Mails zu schreiben. Stattdessen wird empfohlen, sich auf die wesentlichen Punkte zu konzentrieren oder ein persönliches Gespräch zu arrangieren, in welchem Details dann ausführlich besprochen werden können.\n",
    "\n",
    "\n",
    "6) Offene Büros sind für extrovertierte Mitarbeitende ideal. Sie sollten dabei in möglichst „lebendigen“ Bereichen platziert werden, in denen viel Interaktion stattfindet. Ruhigere Ecken sollten für die introvertierten Mitarbeitenden aufgehoben werden. \n",
    "\n",
    "\n",
    "7) Lob auszusprechen ist für die Motivation von introvertierten Mitarbeitenden selbstverständlich ebenso wichtig wie für die von extrovertierten. Da Extrovertierte jedoch ein aktiveres Belohnungssystem besitzen, ist Lob (natürlich sofern es gerechtfertigt ist) bei ihnen gleich doppelt so wirksam. \n",
    "\n",
    "\n",
    "8) Introvertierte sollten ihren extrovertierten Kollegen gegenüber stets bestimmt sein und kommunizieren, wenn sie mehr Zeit, Ruhe o.Ä. für etwas brauchen, auch wenn ihnen das vielleicht unangenehm ist. Möglicherweise ist den Extrovertierten gar nicht bewusst, dass sie ihre introvertierten Kollegen gerade in eine stressige Lage bringen. Solange man höflich bleibt, werden sie danach bestimmt Verständnis zeigen.\n",
    "\n",
    "\n",
    "Dies sind sicherlich nur ein paar Beispiele, um Problemen zwischen Intro- und Extrovertierten am Arbeitsplatz vorzubeugen. In erster Linie gilt stets: Miteinander sprechen! Nur so können Missverständnisse aus dem Weg geräumt werden und eine erfolgreiche Zusammenarbeit entstehen.\n",
    "\n",
    "\n",
    "Zählst du eher zu den Introvertierten oder zu den Extrovertierten? Stimmst du den Empfehlungen zu? Womit könnte man die Liste noch ergänzen? Tausche dich mit den anderen Lernenden aus.\n",
    "\"\"\"\n",
    "\n",
    "text3 = \"\"\"\n",
    "Innovation in der DNA\n",
    "Welche Eigenschaften haben Menschen, die sich durch innovative Ideen auszeichnen? Was haben sie gemeinsam? Ist es möglich, sie unter Tausenden zu erkennen? Eine sechsjährige Studie versuchte, diese Fragen zu beantworten.\n",
    "\n",
    "In dem Bewusstsein, dass Innovationsfähigkeit eine wesentliche Eigenschaft für den Erfolg und das Überleben eines Unternehmens ist, fragen sich Top-Manager/-innen oft, wie sie innovative Mitarbeitende finden sowie selbst innovativer werden können. \n",
    "\n",
    "\n",
    "Drei Universitätsprofessoren und Forscher haben deshalb sechs Jahre lang innovative Unternehmer/-innen und Manager/-innen beobachtet und interviewt, um zu verstehen, was diese voneinander unterscheidet und den einen zum Steve Jobs und die andere zur Besitzerin eines Franchise-Geschäfts macht. Diese Studie führte zur Entdeckung von fünf essenziellen Fähigkeiten, welche diejenigen charakterisieren, die einhellig als Innovatoren bzw. Innovatorinnen angesehen werden und nach Ansicht der Wissenschaftler das besitzen, was sie als \"DNA des Innovators\" bezeichnen:\n",
    "\n",
    "\n",
    "1. Die Fähigkeit, Assoziationen zu bilden bzw. Elemente (Probleme, Ideen, Fragen, ...) zu verknüpfen, die auf den ersten Blick keinen direkten Bezug zueinander haben: Dieses Phänomen wurde von dem Unternehmer Frans Johansson als \"Medici-Effekt\" beschrieben, welcher sich auf die kreative Explosion in Florenz bezieht, als die Medici-Familie Menschen aus verschiedenen Disziplinen (Dichtung, Bildhauerei, Architektur, Philosophie, Malerei,...) zusammenbrachte und durch die Interaktion zwischen verschiedenen Wissens- und Tätigkeitsbereichen eine Periode außergewöhnlicher Kreativität herbeiführte, die man heute als Renaissance kennt. Das Gehirn assoziiert Ideen basierend auf den Erfahrungen, die gemacht wurden. Je vielfältiger diese Erfahrungen sind, desto mehr ist das Gehirn in der Lage, nicht offensichtliche Assoziationen zu erzeugen. \n",
    "\n",
    "\n",
    "2. Die Fähigkeit, Fragen zu stellen: Wie jemand einmal sagte: \"Das Wichtigste ist nicht, die richtigen Antworten zu finden, sondern die richtigen Fragen zu stellen\". Während Unternehmer/-innen sich fragen, wie sie bestehende Prozesse verbessern können, denken Innovatoren und Innovatorinnen darüber nach, wie sie den Status quo und die traditionelle Denkweise in Frage stellen können und fragen sich selbst: \"Wenn wir XY tun würden, was würde dann passieren\"?\n",
    "\n",
    "\n",
    "3. Die Fähigkeit zu beobachten: Innovatoren und Innovatorinnen beobachten sorgfältig die Welt um sich herum, egal ob es sich um potenzielle Kunden, Lieferanten, konkurrierende Unternehmen oder normale Menschen handelt, die arbeiten und ihren täglichen Aktivitäten nachgehen. Dadurch erhalten sie Einblicke und folglich Ideen, wie bestimmte Dinge auf eine neue Art und Weise erledigt werden können.  \n",
    "\n",
    "\n",
    "4. Die Fähigkeit zu experimentieren: Genau wie Wissenschaftler und Wissenschaftlerinnen testen auch Innovatoren und Innovatorinnen aktiv ihre Ideen, erstellen Prototypen und initiieren Pilotprojekte. Das Leben und Arbeiten im Ausland ist beispielsweise eine nützliche Erfahrung, um innovative Ideen zu stimulieren: Es scheint, dass, je mehr Länder eine Person besucht hat, desto wahrscheinlicher ist es, dass sie diese Erfahrungen nutzt, um innovative Dienstleistungen oder Produkte zu erschaffen. Tatsächlich zeigen Untersuchungen, dass Unternehmen, die von CEOs geführt werden, welche vor deren Ernennung mindestens eine internationale Erfahrung gesammelt haben, finanziell besser abschneiden als Unternehmen, die von CEOs ohne diese Erfahrung geführt werden. \n",
    "\n",
    "\n",
    "5. Networking: Innovative Unternehmer/-innen treffen und sprechen mit Menschen aus verschiedenen Berufsfeldern und mit unterschiedlichen Sichtweisen, um ihr Wissen zu erweitern und die Dinge aus einer anderen Perspektive zu sehen.\n",
    "\n",
    "\n",
    "Die gute Nachricht ist, dass wir, auch wenn wir nicht mit der richtigen DNA geboren wurden, trotzdem zu Innovator/-innen werden können, indem wir die fünf oben beschriebenen Fähigkeiten regelmäßig trainieren, sodass die entsprechenden Verhaltensweisen mit der Zeit automatisiert werden. Kurz gesagt: Innovatoren und Innovatorinnen werden nicht als solche geboren, sondern zu diesen gemacht. \n",
    "\n",
    "Pregunta\n",
    "Stimmst du den Forschungsergebnissen zu, dass Innovator/-innen nicht geboren, sondern gemacht werden? Sind deiner Meinung nach noch andere Fähigkeiten erforderlich, um innovative Ideen entwickeln zu können?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "pipeline2(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "pipeline2(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "pipeline2(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordfreq.word_frequency(\"hay\",\"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordfreq.word_frequency(\"había\",\"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordfreq.word_frequency(\"hubo\",\"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordfreq.word_frequency(\"haber\",\"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordfreq.word_frequency(\"abfahren\",\"de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "his = pd.read_csv(\"history.csv\",sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "his[\"highlighted\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sehen\n",
      "sehen\n",
      "Tagen\n",
      "gekommen\n",
      "dort\n",
      "sagte\n",
      "sehen\n",
      "diesen\n",
      "sehen\n",
      "wollen\n",
      "wolle\n",
      "erst\n",
      "lassen\n",
      "sagte\n",
      "weiter\n"
     ]
    }
   ],
   "source": [
    "for i in doc:\n",
    "    if i._.newword:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(doc).apply(basewordfreq).apply(pd.Series)\n",
    "\n",
    "# get a word\n",
    "myword = 'masks'\n",
    "# decide which language data to load\n",
    "# apply it on a word form\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfv2 = dfvocab.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfaux[dfaux[\"highlighted\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True|False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfaux[dfaux[\"highlighted\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfaux[\"highlight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxfreq = dfv2[1].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxfreq.columns = 1, \"times\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxfreq= pd.merge(dfv2[[1,2]].groupby(1)[2].max().reset_index(),auxfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxfreq[\"highlight\"] = auxfreq[2]>0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from german_lemmatizer import lemmatize\n",
    "\n",
    "lem =lemmatize(\n",
    "    ['Johannes war ein guter Schüler', 'Sabiene sang zahlreiche Lieder'],\n",
    "    working_dir='*',\n",
    "    chunk_size=10000,\n",
    "    n_jobs=1,\n",
    "    escape=False,\n",
    "    remove_stop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(doc).apply(processvocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp(\"Morgen rufe ich dich an\")[-1].pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in doc:\n",
    "    if i.pos_ == \"PROPN\":\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newwordchecker(doc,user):\n",
    "    today = date.today()\n",
    "    d1 = today.strftime(\"%Y/%m/%d\")\n",
    "    historyname = \"history.csv\"\n",
    "    targetvocabularyname = user+\"/000_history/targetvocabulary.csv\"\n",
    "    auxiliarname = user+\"/000_history/auxdictionary.csv\"\n",
    "    \n",
    "    \n",
    "    #CREATION/CHARGE DATASETS\n",
    "    aux = pd.read_csv(auxiliarname,sep=\"|\")\n",
    "    targetvocabulary = pd.read_csv(targetvocabularyname,sep=\"|\")\n",
    "    try:\n",
    "        history = pd.read_csv(history, sep ='|')\n",
    "    except:\n",
    "        history = pd.DataFrame(columns = [\"word\",\"pos\",\"firsttime\",\"lasttime\",\"counter_text\",\"counter_word\"])\n",
    "    if \"firsttime\" not in targetvocabulary.columns:\n",
    "        for i in [\"firsttime\",\"lasttime\"]:\n",
    "            targetvocabulary[i] = \"never\"\n",
    "        for i in [\"counter_text\",\"counter_word\"]:\n",
    "            targetvocabulary[i] = 0\n",
    "        \n",
    "    newwords = pd.DataFrame(columns = [\"word\",\"pos\",\"firsttime\",\"lasttime\",\"counter_text\",\"counter_word\"])\n",
    "    oldwords = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for x in doc:\n",
    "        if x.pos_ not in [\"NUM\",\"X\",\"PROPN\",\"SPACE\",\"PART\",\"PUNCT\"]:\n",
    "            if (x.pos_ in [\"NOUN\",\"PROPN\"]):\n",
    "                entries = wordfinder(aux, x.lemma_, \"NOUN\")\n",
    "            elif (x.pos_ in [\"AUX\",\"VERB\"]):\n",
    "                sep = \"REFLEXIVE_VERB\" in x._.att_li[\"aux_labels\"]\n",
    "                entries = wordfinder(aux, x.lemma_.lower(), \"VERB\",x._.att_li[\"aux_string\"] ,sep)\n",
    "            else:\n",
    "                entries = wordfinder(aux, x.lemma.lower(),\"OTHERS_clean_complete\")\n",
    "                \n",
    "            if len(entries) == 0:\n",
    "                continue\n",
    "                \n",
    "            for i in entries:\n",
    "                \n",
    "                selectedrowsvocab = targetvocabulary[targetvocabulary[\"entries\"]==i]\n",
    "            \n",
    "            if (x.pos_ != \"NOUN\") and (x.pos_ != \"PROPN\"):\n",
    "                word =x._.att_li[\"aux_string\"]+x.lemma_.lower()\n",
    "            else:\n",
    "                word = x._.att_li[\"aux_string\"]+x.lemma_\n",
    "            word2 = nlp(word)[0]#.lemma_\n",
    "            if word2.pos_ == x.pos_:\n",
    "                word = word2.lemma_\n",
    "            rowword = wordlist[wordlist[\"word\"]==word]\n",
    "            if (len(rowword)==1):\n",
    "                index = rowword.index[0]\n",
    "                if x.pos_ not in wordlist.loc[index,\"pos\"]:\n",
    "                    wordlist.loc[index,\"pos\"] += \" \"+x.pos_\n",
    "                wordlist.loc[index,\"lasttime\"] = today.strftime(\"%Y/%m/%d\")\n",
    "                if (word not in oldwords):\n",
    "                    wordlist.loc[index,\"counter\"] += 1\n",
    "                    oldwords.append(word)\n",
    "            if len(rowword)==0:\n",
    "                x._.newword= True\n",
    "                if word not in list(newwords[\"word\"]):\n",
    "                    newwords = newwords.append({\"word\":word,\"pos\": x.pos_, \"firsttime\":d1, \"lasttime\":d1,\"counter\":1},ignore_index=True)\n",
    "                else:\n",
    "                    index2 = newwords.loc[newwords[\"word\"]==word].index[0]\n",
    "                    if x.pos_ not in newwords.loc[index2, \"pos\"]:\n",
    "                        newwords.loc[index2,\"pos\"] += \" \"+x.pos_\n",
    "                    \n",
    "    #newvocdf = pd.DataFrame(newwords)\n",
    "    ff = pd.read_csv(vocabfile, sep = \"|\")\n",
    "    report,listenriched = enrichnewvocabulary(newwords, ff)\n",
    "    #render dataframe as html\n",
    "    report = report.drop_duplicates()\n",
    "    html = report.to_html()\n",
    "\n",
    "    #write html to file\n",
    "    text_file = open(folder+\"/report.html\", \"w\",encoding=\"utf-8\")\n",
    "    text_file.write(html)\n",
    "    text_file.close()\n",
    "    \n",
    "    pd.concat([wordlist, report]).to_csv(wordlistname, sep ='|', index= False)\n",
    "\n",
    "    if \"counter\" not in ff.columns:\n",
    "        ff[\"counter\"] = 0\n",
    "        ff[\"firsttime\"] = \"never\"\n",
    "        ff[\"lasttime\"] = \"never\"\n",
    "        \n",
    "    ff.loc[ff[\"entries\"].apply(lambda x: x in listenriched), \"counter\"]+=1\n",
    "    ff.loc[(ff[\"entries\"].apply(lambda x: x in listenriched))&(ff[\"firsttime\"]==\"never\"), \"firsttime\"] = d1\n",
    "    ff.loc[ff[\"entries\"].apply(lambda x: x in listenriched), \"lasttime\"]=d1\n",
    "    ff.to_csv(vocabfile, sep ='|', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordknowledge(x, mode):\n",
    "    if mode == \"writing\":\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
